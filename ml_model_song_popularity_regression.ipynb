{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Regression Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Dataset - Spotify Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "In this task, we will use a sample of 150K records, out of the [\"Spotify Dataset 1921-2020, 600k+ Tracks\"]([https://](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv)) which is available on kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns:\n",
    "\n",
    ">**Target Column** we will predict the following column:\n",
    "- `popularity` (Ranges from 0 to 100), float, representing the popularity of the song in the Spotify platform.\n",
    "\n",
    ">**Numerical Columns**:\n",
    "- `id` (Id of tracks generated by Spotify)\n",
    "- `acousticness` (Ranges from 0 to 1)\n",
    "- `danceability` (Ranges from 0 to 1)\n",
    "- `energy` (Ranges from 0 to 1)\n",
    "- `duration_ms` (Integer typically ranging from 200k to 300k)\n",
    "- `instrumentalness` (Ranges from 0 to 1)\n",
    "- `valence` (Ranges from 0 to 1)\n",
    "- `animality` (Ranges from 0 to 1)\n",
    "- `tempo` (Float typically ranging from 50 to 150)\n",
    "- `liveness` (Ranges from 0 to 1)\n",
    "- `loudness` (Float typically ranging from -60 to 0)\n",
    "- `speechiness` (Ranges from 0 to 1)\n",
    "- `release_year` a column which we are going to extract out of the `Release` column and predict based on song's features.\n",
    "\n",
    "\n",
    "> **Categorical Columns** (string types):\n",
    "- `explicit` (Whether the song is explicit (contains swearing or inappropriate language) or not)\n",
    "  \n",
    "> The following categorical columns will be removed to simplify the task (to many categories):\n",
    "- `artists` (List of artists mentioned)\n",
    "- `track_name` (Name of the song)\n",
    "- `genre` is the genre of the song. String type, Multiclass.<br>\n",
    "- `key` (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1, and so onâ€¦)\n",
    "- `time_signature` A notational convention to specify how many beats are in each bar (or measure). For example, rock music often has a time signature of 4/4, while classical music often has a time signature of 3/4 or 4/4.\n",
    "- `Release` the date which the song was released on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 59770 to 98755\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                5000 non-null   object \n",
      " 1   name              4999 non-null   object \n",
      " 2   popularity        5000 non-null   int64  \n",
      " 3   duration_ms       5000 non-null   int64  \n",
      " 4   explicit          5000 non-null   int64  \n",
      " 5   artists           5000 non-null   object \n",
      " 6   release_date      5000 non-null   object \n",
      " 7   danceability      5000 non-null   float64\n",
      " 8   energy            5000 non-null   float64\n",
      " 9   key               5000 non-null   int64  \n",
      " 10  loudness          5000 non-null   float64\n",
      " 11  speechiness       5000 non-null   float64\n",
      " 12  acousticness      5000 non-null   float64\n",
      " 13  instrumentalness  5000 non-null   float64\n",
      " 14  liveness          5000 non-null   float64\n",
      " 15  valence           5000 non-null   float64\n",
      " 16  tempo             5000 non-null   float64\n",
      " 17  time_signature    5000 non-null   int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 742.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>0vIDmQVcdN5xoKXCTzTciu</td>\n",
       "      <td>L'ombre sur la mesure</td>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>['La Rumeur']</td>\n",
       "      <td>2002-04-12</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>6Kv5DGGNsTmMPwWHDPdquI</td>\n",
       "      <td>Roshni Apni Umangon Ki</td>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>['Noor Jehan']</td>\n",
       "      <td>1943-01-01</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>6FRugAcwKEgQ3r2MkWC5Mm</td>\n",
       "      <td>Kiss the Dirt (Falling Down the Mountain)</td>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>['INXS']</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140509</th>\n",
       "      <td>0GeAGyjTjCufXGm9Q2DNLa</td>\n",
       "      <td>Bisa</td>\n",
       "      <td>36</td>\n",
       "      <td>227657</td>\n",
       "      <td>0</td>\n",
       "      <td>['Billfold']</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.624</td>\n",
       "      <td>92.478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144297</th>\n",
       "      <td>2rvDPgJnBxnkIRpYwVFrY2</td>\n",
       "      <td>Eclipse Total del Amor (Total Eclipse of the H...</td>\n",
       "      <td>55</td>\n",
       "      <td>324493</td>\n",
       "      <td>0</td>\n",
       "      <td>['Yuridia', 'Patricio Borghetti']</td>\n",
       "      <td>2006-10-27</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.508</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.725</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.331</td>\n",
       "      <td>134.927</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "59770   0vIDmQVcdN5xoKXCTzTciu   \n",
       "21362   6Kv5DGGNsTmMPwWHDPdquI   \n",
       "127324  6FRugAcwKEgQ3r2MkWC5Mm   \n",
       "140509  0GeAGyjTjCufXGm9Q2DNLa   \n",
       "144297  2rvDPgJnBxnkIRpYwVFrY2   \n",
       "\n",
       "                                                     name  popularity  \\\n",
       "59770                               L'ombre sur la mesure          34   \n",
       "21362                              Roshni Apni Umangon Ki           0   \n",
       "127324          Kiss the Dirt (Falling Down the Mountain)          26   \n",
       "140509                                               Bisa          36   \n",
       "144297  Eclipse Total del Amor (Total Eclipse of the H...          55   \n",
       "\n",
       "        duration_ms  explicit                            artists release_date  \\\n",
       "59770        198613         0                      ['La Rumeur']   2002-04-12   \n",
       "21362        189013         0                     ['Noor Jehan']   1943-01-01   \n",
       "127324       236160         0                           ['INXS']         1985   \n",
       "140509       227657         0                       ['Billfold']   2013-01-01   \n",
       "144297       324493         0  ['Yuridia', 'Patricio Borghetti']   2006-10-27   \n",
       "\n",
       "        danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "59770          0.695   0.746    1    -5.119       0.3920      0.404000   \n",
       "21362          0.434   0.225   10   -16.287       0.0418      0.993000   \n",
       "127324         0.697   0.695    6    -8.211       0.0465      0.032500   \n",
       "140509         0.372   0.945    2    -2.431       0.0484      0.000084   \n",
       "144297         0.688   0.508    8    -6.725       0.0286      0.218000   \n",
       "\n",
       "        instrumentalness  liveness  valence    tempo  time_signature  \n",
       "59770           0.000048    0.0979    0.720  169.813               4  \n",
       "21362           0.930000    0.2390    0.814   72.649               3  \n",
       "127324          0.008280    0.1140    0.605  115.813               4  \n",
       "140509          0.025300    0.3800    0.624   92.478               4  \n",
       "144297          0.000000    0.0979    0.331  134.927               4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_url = 'https://raw.githubusercontent.com/FreeDataSets/DataPool/main/tracks_150000.csv' # this is the url for the dataset\n",
    "reg_df = pd.read_csv(reg_url).sample(5000,random_state=42) # In order to reduce the size of the dataset, we are taking a random sample of 5000 rows from the dataset\n",
    "\n",
    "# a preview of the dataframe\n",
    "reg_df.info() \n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>0vIDmQVcdN5xoKXCTzTciu</td>\n",
       "      <td>L'ombre sur la mesure</td>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>['La Rumeur']</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>6Kv5DGGNsTmMPwWHDPdquI</td>\n",
       "      <td>Roshni Apni Umangon Ki</td>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>['Noor Jehan']</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>6FRugAcwKEgQ3r2MkWC5Mm</td>\n",
       "      <td>Kiss the Dirt (Falling Down the Mountain)</td>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>['INXS']</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140509</th>\n",
       "      <td>0GeAGyjTjCufXGm9Q2DNLa</td>\n",
       "      <td>Bisa</td>\n",
       "      <td>36</td>\n",
       "      <td>227657</td>\n",
       "      <td>0</td>\n",
       "      <td>['Billfold']</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.624</td>\n",
       "      <td>92.478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144297</th>\n",
       "      <td>2rvDPgJnBxnkIRpYwVFrY2</td>\n",
       "      <td>Eclipse Total del Amor (Total Eclipse of the H...</td>\n",
       "      <td>55</td>\n",
       "      <td>324493</td>\n",
       "      <td>0</td>\n",
       "      <td>['Yuridia', 'Patricio Borghetti']</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.508</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.725</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.331</td>\n",
       "      <td>134.927</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "59770   0vIDmQVcdN5xoKXCTzTciu   \n",
       "21362   6Kv5DGGNsTmMPwWHDPdquI   \n",
       "127324  6FRugAcwKEgQ3r2MkWC5Mm   \n",
       "140509  0GeAGyjTjCufXGm9Q2DNLa   \n",
       "144297  2rvDPgJnBxnkIRpYwVFrY2   \n",
       "\n",
       "                                                     name  popularity  \\\n",
       "59770                               L'ombre sur la mesure          34   \n",
       "21362                              Roshni Apni Umangon Ki           0   \n",
       "127324          Kiss the Dirt (Falling Down the Mountain)          26   \n",
       "140509                                               Bisa          36   \n",
       "144297  Eclipse Total del Amor (Total Eclipse of the H...          55   \n",
       "\n",
       "        duration_ms  explicit                            artists  \\\n",
       "59770        198613         0                      ['La Rumeur']   \n",
       "21362        189013         0                     ['Noor Jehan']   \n",
       "127324       236160         0                           ['INXS']   \n",
       "140509       227657         0                       ['Billfold']   \n",
       "144297       324493         0  ['Yuridia', 'Patricio Borghetti']   \n",
       "\n",
       "        danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "59770          0.695   0.746    1    -5.119       0.3920      0.404000   \n",
       "21362          0.434   0.225   10   -16.287       0.0418      0.993000   \n",
       "127324         0.697   0.695    6    -8.211       0.0465      0.032500   \n",
       "140509         0.372   0.945    2    -2.431       0.0484      0.000084   \n",
       "144297         0.688   0.508    8    -6.725       0.0286      0.218000   \n",
       "\n",
       "        instrumentalness  liveness  valence    tempo  time_signature  \n",
       "59770           0.000048    0.0979    0.720  169.813               4  \n",
       "21362           0.930000    0.2390    0.814   72.649               3  \n",
       "127324          0.008280    0.1140    0.605  115.813               4  \n",
       "140509          0.025300    0.3800    0.624   92.478               4  \n",
       "144297          0.000000    0.0979    0.331  134.927               4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert Release to date and then extract year from it - written with the help of CHATGPT\n",
    "reg_df['release_date'] = pd.to_datetime(reg_df['release_date'])\n",
    "reg_df['release_date'] = reg_df['release_date'].dt.year\n",
    "reg_df.drop('release_date', axis=1, inplace=True) \n",
    "reg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 59770 to 98755\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        5000 non-null   int64  \n",
      " 1   duration_ms       5000 non-null   int64  \n",
      " 2   explicit          5000 non-null   int64  \n",
      " 3   danceability      5000 non-null   float64\n",
      " 4   energy            5000 non-null   float64\n",
      " 5   loudness          5000 non-null   float64\n",
      " 6   speechiness       5000 non-null   float64\n",
      " 7   acousticness      5000 non-null   float64\n",
      " 8   instrumentalness  5000 non-null   float64\n",
      " 9   liveness          5000 non-null   float64\n",
      " 10  valence           5000 non-null   float64\n",
      " 11  tempo             5000 non-null   float64\n",
      "dtypes: float64(9), int64(3)\n",
      "memory usage: 507.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  loudness  \\\n",
       "59770           34       198613         0         0.695   0.746    -5.119   \n",
       "21362            0       189013         0         0.434   0.225   -16.287   \n",
       "127324          26       236160         0         0.697   0.695    -8.211   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "59770        0.3920        0.4040          0.000048    0.0979    0.720   \n",
       "21362        0.0418        0.9930          0.930000    0.2390    0.814   \n",
       "127324       0.0465        0.0325          0.008280    0.1140    0.605   \n",
       "\n",
       "          tempo  \n",
       "59770   169.813  \n",
       "21362    72.649  \n",
       "127324  115.813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# written with the help of CHATGPT\n",
    "reg_df.drop(['name', 'artists','id','release_date', 'artists_id','genre','key','time_signature'], axis=1, inplace=True, errors='ignore') # Removing Categorical features with more then 10 unique values\n",
    "reg_df.info()\n",
    "reg_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable \n",
    "Xreg = reg_df.drop('popularity', axis=1) # features\n",
    "yreg = reg_df['popularity'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize the data as asked in question 9, although it creates a problem of data leakage as we are using the test data to fit the scaler\n",
    "scaler_reg = StandardScaler().fit(Xreg)\n",
    "Xreg_scaled = scaler_reg.transform(Xreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "Xreg_train_scaled, Xreg_test_scaled, yreg_train, yreg_test = train_test_split(Xreg, yreg, test_size=0.2, random_state=42)\n",
    "# end of Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10) Applying a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lin_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11) Evaluating the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to save and compare regression metrics # written with the help of CHATGPT\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "def calculate_and_append_metrics(model_name, model, X_train, y_train, X_test, y_test, train_results_df, test_results_df):\n",
    "    # Calculate metrics for the training dataset\n",
    "    train_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_train, model.predict(X_train))],\n",
    "        'RMSE': [mean_squared_error(y_train, model.predict(X_train), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_train, model.predict(X_train))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_train, model.predict(X_train))]\n",
    "    })\n",
    "\n",
    "    # Calculate metrics for the test dataset\n",
    "    test_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_test, model.predict(X_test))],\n",
    "        'RMSE': [mean_squared_error(y_test, model.predict(X_test), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_test, model.predict(X_test))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_test, model.predict(X_test))]\n",
    "    })\n",
    "\n",
    "    # Concatenate metrics to the respective DataFrames\n",
    "    train_results_df = pd.concat([train_results_df, train_metrics], ignore_index=True)\n",
    "    test_results_df = pd.concat([test_results_df, test_metrics], ignore_index=True)\n",
    "\n",
    "    return train_results_df, test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.215364</td>\n",
       "      <td>16.395671</td>\n",
       "      <td>13.33369</td>\n",
       "      <td>6.955872e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE       MAE          MAPE\n",
       "0  Linear Regression  0.215364  16.395671  13.33369  6.955872e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>16.642758</td>\n",
       "      <td>13.47217</td>\n",
       "      <td>8.135445e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE       MAE          MAPE\n",
       "0  Linear Regression  0.180108  16.642758  13.47217  8.135445e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics - # written with the help of CHATGPT\n",
    "\n",
    "# Create empty DataFrames to store the results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame()\n",
    "\n",
    "# Calculate metrics for the Linear Regression model\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('Linear Regression', lin_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12) Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-259.500 total time=   0.0s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-243.760 total time=   0.0s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-290.510 total time=   0.0s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-290.418 total time=   0.0s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-268.690 total time=   0.0s\n",
      "[CV 1/5] END poly__degree=2;, score=-2214713034893210943488.000 total time=   0.0s\n",
      "[CV 2/5] END .poly__degree=2;, score=-7626636628438739968.000 total time=   0.0s\n",
      "[CV 3/5] END poly__degree=2;, score=-718158577387438398767104.000 total time=   0.0s\n",
      "[CV 4/5] END poly__degree=2;, score=-2075636861597463085056.000 total time=   0.0s\n",
      "[CV 5/5] END poly__degree=2;, score=-150930781671070040064.000 total time=   0.0s\n",
      "[CV 1/5] END poly__degree=3;, score=-18382688336652732033152605198860736412369551360.000 total time=   0.4s\n",
      "[CV 2/5] END poly__degree=3;, score=-14143810482358180635016621902191950835755253760.000 total time=   0.5s\n",
      "[CV 3/5] END poly__degree=3;, score=-92472896146876405633167443658529360176308289536.000 total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END poly__degree=3;, score=-2881105803374864425324655381264290272883245056.000 total time=   0.6s\n",
      "[CV 5/5] END poly__degree=3;, score=-38454228256846726506860670370182811892056064.000 total time=   1.4s\n",
      "[CV 1/5] END poly__degree=4;, score=-1509188043017450715834799534653956518465975182942249246117864389663770279936.000 total time=   8.9s\n",
      "[CV 2/5] END poly__degree=4;, score=-4217073431152792579966730576015937146675079171696061741466623133100598808805376.000 total time=   4.0s\n",
      "[CV 3/5] END poly__degree=4;, score=-30241197849341540425393467581989393528222544937444653485225800637605957305630720.000 total time=   5.7s\n",
      "[CV 4/5] END poly__degree=4;, score=-203193510245181745625155295960456935485562200448622379413181455496546165767274496.000 total time=   5.1s\n",
      "[CV 5/5] END poly__degree=4;, score=-166586823100332829018647640113861196375133963499380203970548259341602973024256.000 total time=   6.1s\n",
      "RidgeCV Results:\n",
      "Best Polynomial Degree: 1\n",
      "Best Alpha for RidgeCV: 1.0\n",
      "Best Negative MSE: 16.44917962731788\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ridge Regression - written with the help of CHATGPT \"\"\"\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "degrees = range(1, 5)\n",
    "\n",
    "# Create a RidgeCV model with cross-validation\n",
    "ridge_cv = RidgeCV([0.01, 0.1, 1, 10])\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('poly', poly),('ridge_cv', ridge_cv)])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "ridge_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error',verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "ridge_grid_search.fit(X, y)\n",
    "warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for RidgeCV\n",
    "best_degree = ridge_grid_search.best_params_['poly__degree']\n",
    "best_alpha = ridge_grid_search.best_estimator_.named_steps['ridge_cv'].alpha_\n",
    "\n",
    "# Print the results\n",
    "print(\"RidgeCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for RidgeCV:\", best_alpha)\n",
    "print(\"Best Negative MSE:\", (-ridge_grid_search.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-259.552 total time=   0.0s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-243.930 total time=   0.0s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-290.467 total time=   0.0s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-290.166 total time=   0.0s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-269.073 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .................poly__degree=2;, score=-247.824 total time=   0.4s\n",
      "[CV 2/5] END .................poly__degree=2;, score=-229.817 total time=   0.3s\n",
      "[CV 3/5] END .................poly__degree=2;, score=-265.448 total time=   0.3s\n",
      "[CV 4/5] END .................poly__degree=2;, score=-267.806 total time=   0.4s\n",
      "[CV 5/5] END .................poly__degree=2;, score=-255.888 total time=   0.4s\n",
      "/nLassoCV Results:\n",
      "Best Polynomial Degree: 2\n",
      "Best Polynomial Degree: 2\n",
      "Best Alpha for LassoCV: 0.01\n",
      "Best RMSE: 15.9171798341219\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lasso Regression - written with the help of CHATGPT \"\"\"\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "last_degree = 3\n",
    "degrees = range(1, last_degree)\n",
    "\n",
    "# Create a LassoCV model with cross-validation\n",
    "lasso_cv = LassoCV(alphas=[0.01,0.1, 1.0, 10.0]\n",
    "                #    max_iter=100000\n",
    "                   )\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('lasso_cv', lasso_cv)\n",
    "])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "lasso_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter out ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "lasso_grid_search.fit(X, y)\n",
    "\n",
    "# Optionally, you can reset the warning filters to their original state\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for LassoCV\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "best_alpha = lasso_grid_search.best_estimator_.named_steps['lasso_cv'].alpha_\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "\n",
    "# Print the results\n",
    "print(\"/nLassoCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for LassoCV:\", best_alpha)\n",
    "print(\"Best RMSE:\", (-lasso_grid_search.best_score_)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13) About Regularization\n",
    "\n",
    "The problem with a complex model of second order or higher is the risk of **Overfitting:**\n",
    "\n",
    "When a model fits the *noise* and random fluctuations in the training data rather than capturing the underlying patterns that are truly representative of the target population. \n",
    "\n",
    "A *solution* to the overfitting risk is **Regularization**: \n",
    "Adding a penalty term to the model's *loss function*, encouraging the model to have smaller parameter values or simpler parameter patterns, discourages overfitting.\n",
    "\n",
    "**Lasso (Least Absolute Shrinkage and Selection Operator):** adds a penalty term $||Î²||_1$ which is the sum of the absolute values of the coefficients.\n",
    "**Ridge** adds a penalty term $||Î²||_2^2$ which is the sum of the squared values of the coefficients.\n",
    "Lasso is better for Feature Selection and ridge is better for datasets with Multicollinearity, because Lasso tends to drive the coefficients of irrelevant features to exactly zero, effectively performing feature selection, while Ridge doesn't. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14) Evaluating polynomial regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.215364</td>\n",
       "      <td>16.395671</td>\n",
       "      <td>13.333690</td>\n",
       "      <td>6.955872e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.215355</td>\n",
       "      <td>16.395765</td>\n",
       "      <td>13.334775</td>\n",
       "      <td>6.960283e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.282024</td>\n",
       "      <td>15.683754</td>\n",
       "      <td>12.677475</td>\n",
       "      <td>5.940044e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.215364  16.395671  13.333690  6.955872e+15\n",
       "1            RidgeCV  0.215355  16.395765  13.334775  6.960283e+15\n",
       "2            LassoCV  0.282024  15.683754  12.677475  5.940044e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>16.642758</td>\n",
       "      <td>13.472170</td>\n",
       "      <td>8.135445e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.180052</td>\n",
       "      <td>16.643326</td>\n",
       "      <td>13.473695</td>\n",
       "      <td>8.141552e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.241372</td>\n",
       "      <td>16.008899</td>\n",
       "      <td>12.977174</td>\n",
       "      <td>7.148455e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.180108  16.642758  13.472170  8.135445e+15\n",
       "1            RidgeCV  0.180052  16.643326  13.473695  8.141552e+15\n",
       "2            LassoCV  0.241372  16.008899  12.977174  7.148455e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics - written with the help of CHATGPT\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RidgeCV', ridge_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('LassoCV', lasso_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15) Applying RandomForrestRegressor and Xgbregressor\n",
    "We will use pre-tuned xgb and rf models and also hyperparameter tuned xgb and rf models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# run Xgboost regressor\n",
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-259.444 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-252.163 total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-299.956 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-280.882 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-276.123 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-245.372 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-235.511 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-280.484 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-268.718 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-258.254 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-254.206 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-245.505 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-293.423 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-274.984 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-270.259 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-240.640 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-229.436 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-276.432 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-262.748 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-251.530 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-250.637 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-241.823 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-290.472 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-276.813 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-267.129 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-238.583 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-226.806 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-274.100 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-265.069 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-250.074 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-241.387 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-224.966 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-270.608 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-260.640 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-250.454 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-246.868 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-229.679 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-274.807 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-265.134 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-254.046 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-238.317 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-228.229 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-269.318 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-264.985 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-253.827 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-247.372 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-234.965 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-277.814 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-273.696 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-261.232 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-252.103 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-230.476 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-274.948 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-266.244 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-254.452 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-262.595 total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-233.261 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-283.874 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-272.669 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-261.079 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-248.664 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-230.533 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-277.067 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-267.288 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-254.803 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-261.704 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-234.376 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-285.660 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-275.560 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-266.799 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-251.796 total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-234.137 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-282.358 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-277.427 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-264.108 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-264.000 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-242.179 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-296.503 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-291.665 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-273.164 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-260.486 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-238.350 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-285.970 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-280.486 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-272.600 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-275.382 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-248.128 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-296.904 total time=   0.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-292.044 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-286.005 total time=   0.4s\n",
      "Best parameters for XGBoost:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best RMSE for XGBoost: 15.799081786318984\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Tuning the XGBoost and Random Forest Regressors\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg_s = XGBRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_reg, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "xgb_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"Best parameters for XGBoost:\")\n",
    "print(xgb_grid_search.best_params_)\n",
    "print(\"Best RMSE for XGBoost:\", (-xgb_grid_search.best_score_) ** 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-246.902 total time=   1.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-246.931 total time=   0.8s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-284.499 total time=   0.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-277.811 total time=   0.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-260.486 total time=   0.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-246.371 total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-246.289 total time=   1.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-285.760 total time=   1.5s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-277.162 total time=   1.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-260.972 total time=   2.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-246.792 total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-246.911 total time=   1.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-286.075 total time=   1.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-276.267 total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-260.998 total time=   0.8s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-246.726 total time=   1.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-246.865 total time=   1.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-284.842 total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-277.416 total time=   1.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-260.482 total time=   1.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-246.626 total time=   0.5s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-246.269 total time=   0.5s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-284.140 total time=   0.9s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-277.132 total time=   1.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-260.886 total time=   0.9s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-246.491 total time=   1.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-247.030 total time=   2.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-285.527 total time=   3.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-277.511 total time=   2.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-260.617 total time=   1.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-241.530 total time=   0.9s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-237.753 total time=   1.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-279.456 total time=   0.8s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-270.003 total time=   1.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-255.656 total time=   1.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-240.420 total time=   1.8s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-237.185 total time=   1.8s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-278.852 total time=   3.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-270.151 total time=   2.6s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-254.455 total time=   2.7s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-240.868 total time=   1.0s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-237.208 total time=   1.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-279.084 total time=   0.8s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-269.999 total time=   0.8s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-254.626 total time=   1.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-240.855 total time=   3.3s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-237.542 total time=   1.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-277.947 total time=   1.8s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-269.613 total time=   1.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-254.956 total time=   2.0s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-240.127 total time=   1.7s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-236.918 total time=   1.1s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-278.737 total time=   1.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-269.022 total time=   1.7s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-255.551 total time=   1.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-240.639 total time=   1.7s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-237.795 total time=   2.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-279.217 total time=   2.3s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-269.832 total time=   1.7s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-254.737 total time=   2.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-238.673 total time=   1.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-232.679 total time=   1.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-275.030 total time=   1.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-266.183 total time=   1.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-251.384 total time=   1.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-237.985 total time=   2.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-232.268 total time=   2.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-273.363 total time=   3.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-266.381 total time=   2.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-250.716 total time=   2.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-236.931 total time=   1.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-230.783 total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-272.970 total time=   1.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-266.993 total time=   1.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-251.499 total time=   0.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-238.677 total time=   1.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-231.047 total time=   1.8s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-272.528 total time=   2.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-266.284 total time=   2.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-251.246 total time=   1.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-237.310 total time=   0.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-231.577 total time=   0.8s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-272.354 total time=   1.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-265.643 total time=   1.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-251.162 total time=   1.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-237.904 total time=   2.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-233.003 total time=   3.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-271.705 total time=   2.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-266.144 total time=   2.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-250.687 total time=   1.7s\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best RMSE for Random Forest: 15.862189910776793\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest Regressor Hyperparameter Tuning\"\"\" # written with the help of CHATGPT\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [ 3,4, 5],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest regressor\n",
    "rf_reg_s = RandomForestRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_reg_s, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "rf_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"\\nBest parameters for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Best RMSE for Random Forest:\", (-rf_grid_search.best_score_) ** 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q16) Evaluating new regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.215364</td>\n",
       "      <td>16.395671</td>\n",
       "      <td>13.333690</td>\n",
       "      <td>6.955872e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.215355</td>\n",
       "      <td>16.395765</td>\n",
       "      <td>13.334775</td>\n",
       "      <td>6.960283e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.282024</td>\n",
       "      <td>15.683754</td>\n",
       "      <td>12.677475</td>\n",
       "      <td>5.940044e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.899288</td>\n",
       "      <td>5.874019</td>\n",
       "      <td>4.651374</td>\n",
       "      <td>1.977486e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.920385</td>\n",
       "      <td>5.222683</td>\n",
       "      <td>3.842679</td>\n",
       "      <td>1.310846e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.338465</td>\n",
       "      <td>15.054672</td>\n",
       "      <td>12.120803</td>\n",
       "      <td>5.159069e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.401988</td>\n",
       "      <td>14.313634</td>\n",
       "      <td>11.471913</td>\n",
       "      <td>4.721605e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.215364  16.395671  13.333690  6.955872e+15\n",
       "1                      RidgeCV  0.215355  16.395765  13.334775  6.960283e+15\n",
       "2                      LassoCV  0.282024  15.683754  12.677475  5.940044e+15\n",
       "3        RandomForestRegressor  0.899288   5.874019   4.651374  1.977486e+15\n",
       "4                 XGBRegressor  0.920385   5.222683   3.842679  1.310846e+15\n",
       "5  RandomForestRegressor_tuned  0.338465  15.054672  12.120803  5.159069e+15\n",
       "6           XGBRegressor_tuned  0.401988  14.313634  11.471913  4.721605e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>16.642758</td>\n",
       "      <td>13.472170</td>\n",
       "      <td>8.135445e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.180052</td>\n",
       "      <td>16.643326</td>\n",
       "      <td>13.473695</td>\n",
       "      <td>8.141552e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.241372</td>\n",
       "      <td>16.008899</td>\n",
       "      <td>12.977174</td>\n",
       "      <td>7.148455e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.253572</td>\n",
       "      <td>15.879655</td>\n",
       "      <td>12.746340</td>\n",
       "      <td>6.804173e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>16.891544</td>\n",
       "      <td>13.445390</td>\n",
       "      <td>6.128284e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.243241</td>\n",
       "      <td>15.989172</td>\n",
       "      <td>12.922416</td>\n",
       "      <td>6.890332e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.264142</td>\n",
       "      <td>15.766823</td>\n",
       "      <td>12.671418</td>\n",
       "      <td>6.610720e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.180108  16.642758  13.472170  8.135445e+15\n",
       "1                      RidgeCV  0.180052  16.643326  13.473695  8.141552e+15\n",
       "2                      LassoCV  0.241372  16.008899  12.977174  7.148455e+15\n",
       "3        RandomForestRegressor  0.253572  15.879655  12.746340  6.804173e+15\n",
       "4                 XGBRegressor  0.155413  16.891544  13.445390  6.128284e+15\n",
       "5  RandomForestRegressor_tuned  0.243241  15.989172  12.922416  6.890332e+15\n",
       "6           XGBRegressor_tuned  0.264142  15.766823  12.671418  6.610720e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics for the 4 latest models and append them to the results DataFrame - written with the help of CHATGPT\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor', rf_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor', xgb_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor_tuned', rf_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor_tuned', xgb_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17) Choosing the best model\n",
    "\n",
    "The best performing model is the XGBRegressor_tuned, with the lowest RMSE and MAE values on the test set, as well as the highest $R^2$ score.\n",
    "Except the non-tuned XGBRegressor, all of the models did not over-fit. Never the less, all of the models have low goodness of fit.\n",
    "\n",
    "* $R^2$ quantifies the proportion of the variance in the dependent variable that is explained by the independent variables in our model. In this case we witness poor fit. \n",
    "* Root Mean Square Error (RMSE) is a metric used to measure the average magnitude of the errors between predicted and actual values in a regression or forecasting problem, with lower values indicating better model accuracy. In our model we used RMSE as the main target function.\n",
    "* MAE provides a straightforward measure of how far, on average, the model's predictions are from the actual values. It helps assess the model's ability to make accurate predictions while considering both overestimations and underestimations equally. Our MAE values turned relatively low, indicating accurate models.\n",
    "* MAPE is a metric of the accuracy of predictions in relative terms. It tells us how much, on average, the predictions deviate from the actual values as a percentage of the actual values. All of our models reached small MAPE values, indicating relatively accurate predictions. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
