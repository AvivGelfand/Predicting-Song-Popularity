{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Regression Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing general python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing libraries for data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing libraries for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing libraries for model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "# importing libraries for model tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# importing tensorflow libraries for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset - Spotify Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "In this task, we will use a sample of 150K records, out of the [\"Spotify Dataset 1921-2020, 600k+ Tracks\"](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv) which is available on kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns:\n",
    "\n",
    ">**Target Column** we will predict the following column:\n",
    "- `popularity` (Ranges from 0 to 100), float, representing the popularity of the song in the Spotify platform.\n",
    "\n",
    ">**Numerical Columns**:\n",
    "- `id` (Id of tracks generated by Spotify)\n",
    "- `acousticness` (Ranges from 0 to 1)\n",
    "- `danceability` (Ranges from 0 to 1)\n",
    "- `energy` (Ranges from 0 to 1)\n",
    "- `duration_ms` (Integer typically ranging from 200k to 300k)\n",
    "- `instrumentalness` (Ranges from 0 to 1)\n",
    "- `valence` (Ranges from 0 to 1)\n",
    "- `animality` (Ranges from 0 to 1)\n",
    "- `tempo` (Float typically ranging from 50 to 150)\n",
    "- `liveness` (Ranges from 0 to 1)\n",
    "- `loudness` (Float typically ranging from -60 to 0)\n",
    "- `speechiness` (Ranges from 0 to 1)\n",
    "- `release_year` a column which we are going to extract out of the `Release` column and predict based on song's features.\n",
    "\n",
    "\n",
    "> **Categorical Columns** (string types):\n",
    "- `explicit` (Whether the song is explicit (contains swearing or inappropriate language) or not)\n",
    "  \n",
    "> The following categorical columns will be removed to simplify the task (to many categories):\n",
    "- `artists` (List of artists mentioned)\n",
    "- `track_name` (Name of the song)\n",
    "- `genre` is the genre of the song. String type, Multiclass.<br>\n",
    "- `key` (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1, and so onâ€¦)\n",
    "- `time_signature` A notational convention to specify how many beats are in each bar (or measure). For example, rock music often has a time signature of 4/4, while classical music often has a time signature of 3/4 or 4/4.\n",
    "- `Release` the date which the song was released on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 59770 to 93473\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                10000 non-null  object \n",
      " 1   name              9998 non-null   object \n",
      " 2   popularity        10000 non-null  int64  \n",
      " 3   duration_ms       10000 non-null  int64  \n",
      " 4   explicit          10000 non-null  int64  \n",
      " 5   artists           10000 non-null  object \n",
      " 6   release_date      10000 non-null  object \n",
      " 7   danceability      10000 non-null  float64\n",
      " 8   energy            10000 non-null  float64\n",
      " 9   key               10000 non-null  int64  \n",
      " 10  loudness          10000 non-null  float64\n",
      " 11  speechiness       10000 non-null  float64\n",
      " 12  acousticness      10000 non-null  float64\n",
      " 13  instrumentalness  10000 non-null  float64\n",
      " 14  liveness          10000 non-null  float64\n",
      " 15  valence           10000 non-null  float64\n",
      " 16  tempo             10000 non-null  float64\n",
      " 17  time_signature    10000 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>0vIDmQVcdN5xoKXCTzTciu</td>\n",
       "      <td>L'ombre sur la mesure</td>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>['La Rumeur']</td>\n",
       "      <td>2002-04-12</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>6Kv5DGGNsTmMPwWHDPdquI</td>\n",
       "      <td>Roshni Apni Umangon Ki</td>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>['Noor Jehan']</td>\n",
       "      <td>1943-01-01</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>6FRugAcwKEgQ3r2MkWC5Mm</td>\n",
       "      <td>Kiss the Dirt (Falling Down the Mountain)</td>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>['INXS']</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140509</th>\n",
       "      <td>0GeAGyjTjCufXGm9Q2DNLa</td>\n",
       "      <td>Bisa</td>\n",
       "      <td>36</td>\n",
       "      <td>227657</td>\n",
       "      <td>0</td>\n",
       "      <td>['Billfold']</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.624</td>\n",
       "      <td>92.478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144297</th>\n",
       "      <td>2rvDPgJnBxnkIRpYwVFrY2</td>\n",
       "      <td>Eclipse Total del Amor (Total Eclipse of the H...</td>\n",
       "      <td>55</td>\n",
       "      <td>324493</td>\n",
       "      <td>0</td>\n",
       "      <td>['Yuridia', 'Patricio Borghetti']</td>\n",
       "      <td>2006-10-27</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.508</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.725</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.331</td>\n",
       "      <td>134.927</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "59770   0vIDmQVcdN5xoKXCTzTciu   \n",
       "21362   6Kv5DGGNsTmMPwWHDPdquI   \n",
       "127324  6FRugAcwKEgQ3r2MkWC5Mm   \n",
       "140509  0GeAGyjTjCufXGm9Q2DNLa   \n",
       "144297  2rvDPgJnBxnkIRpYwVFrY2   \n",
       "\n",
       "                                                     name  popularity  \\\n",
       "59770                               L'ombre sur la mesure          34   \n",
       "21362                              Roshni Apni Umangon Ki           0   \n",
       "127324          Kiss the Dirt (Falling Down the Mountain)          26   \n",
       "140509                                               Bisa          36   \n",
       "144297  Eclipse Total del Amor (Total Eclipse of the H...          55   \n",
       "\n",
       "        duration_ms  explicit                            artists release_date  \\\n",
       "59770        198613         0                      ['La Rumeur']   2002-04-12   \n",
       "21362        189013         0                     ['Noor Jehan']   1943-01-01   \n",
       "127324       236160         0                           ['INXS']         1985   \n",
       "140509       227657         0                       ['Billfold']   2013-01-01   \n",
       "144297       324493         0  ['Yuridia', 'Patricio Borghetti']   2006-10-27   \n",
       "\n",
       "        danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "59770          0.695   0.746    1    -5.119       0.3920      0.404000   \n",
       "21362          0.434   0.225   10   -16.287       0.0418      0.993000   \n",
       "127324         0.697   0.695    6    -8.211       0.0465      0.032500   \n",
       "140509         0.372   0.945    2    -2.431       0.0484      0.000084   \n",
       "144297         0.688   0.508    8    -6.725       0.0286      0.218000   \n",
       "\n",
       "        instrumentalness  liveness  valence    tempo  time_signature  \n",
       "59770           0.000048    0.0979    0.720  169.813               4  \n",
       "21362           0.930000    0.2390    0.814   72.649               3  \n",
       "127324          0.008280    0.1140    0.605  115.813               4  \n",
       "140509          0.025300    0.3800    0.624   92.478               4  \n",
       "144297          0.000000    0.0979    0.331  134.927               4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_url = 'https://raw.githubusercontent.com/FreeDataSets/DataPool/main/tracks_150000.csv' # this is the url for the dataset\n",
    "reg_df = pd.read_csv(reg_url).sample(10000,random_state=42) # In order to reduce the size of the dataset, we are taking a random sample of 5000 rows from the dataset\n",
    "\n",
    "# a preview of the dataframe\n",
    "reg_df.info() \n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>0vIDmQVcdN5xoKXCTzTciu</td>\n",
       "      <td>L'ombre sur la mesure</td>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>['La Rumeur']</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>6Kv5DGGNsTmMPwWHDPdquI</td>\n",
       "      <td>Roshni Apni Umangon Ki</td>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>['Noor Jehan']</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>10</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>6FRugAcwKEgQ3r2MkWC5Mm</td>\n",
       "      <td>Kiss the Dirt (Falling Down the Mountain)</td>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>['INXS']</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140509</th>\n",
       "      <td>0GeAGyjTjCufXGm9Q2DNLa</td>\n",
       "      <td>Bisa</td>\n",
       "      <td>36</td>\n",
       "      <td>227657</td>\n",
       "      <td>0</td>\n",
       "      <td>['Billfold']</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.945</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.431</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.624</td>\n",
       "      <td>92.478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144297</th>\n",
       "      <td>2rvDPgJnBxnkIRpYwVFrY2</td>\n",
       "      <td>Eclipse Total del Amor (Total Eclipse of the H...</td>\n",
       "      <td>55</td>\n",
       "      <td>324493</td>\n",
       "      <td>0</td>\n",
       "      <td>['Yuridia', 'Patricio Borghetti']</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.508</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.725</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.331</td>\n",
       "      <td>134.927</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "59770   0vIDmQVcdN5xoKXCTzTciu   \n",
       "21362   6Kv5DGGNsTmMPwWHDPdquI   \n",
       "127324  6FRugAcwKEgQ3r2MkWC5Mm   \n",
       "140509  0GeAGyjTjCufXGm9Q2DNLa   \n",
       "144297  2rvDPgJnBxnkIRpYwVFrY2   \n",
       "\n",
       "                                                     name  popularity  \\\n",
       "59770                               L'ombre sur la mesure          34   \n",
       "21362                              Roshni Apni Umangon Ki           0   \n",
       "127324          Kiss the Dirt (Falling Down the Mountain)          26   \n",
       "140509                                               Bisa          36   \n",
       "144297  Eclipse Total del Amor (Total Eclipse of the H...          55   \n",
       "\n",
       "        duration_ms  explicit                            artists  \\\n",
       "59770        198613         0                      ['La Rumeur']   \n",
       "21362        189013         0                     ['Noor Jehan']   \n",
       "127324       236160         0                           ['INXS']   \n",
       "140509       227657         0                       ['Billfold']   \n",
       "144297       324493         0  ['Yuridia', 'Patricio Borghetti']   \n",
       "\n",
       "        danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "59770          0.695   0.746    1    -5.119       0.3920      0.404000   \n",
       "21362          0.434   0.225   10   -16.287       0.0418      0.993000   \n",
       "127324         0.697   0.695    6    -8.211       0.0465      0.032500   \n",
       "140509         0.372   0.945    2    -2.431       0.0484      0.000084   \n",
       "144297         0.688   0.508    8    -6.725       0.0286      0.218000   \n",
       "\n",
       "        instrumentalness  liveness  valence    tempo  time_signature  \n",
       "59770           0.000048    0.0979    0.720  169.813               4  \n",
       "21362           0.930000    0.2390    0.814   72.649               3  \n",
       "127324          0.008280    0.1140    0.605  115.813               4  \n",
       "140509          0.025300    0.3800    0.624   92.478               4  \n",
       "144297          0.000000    0.0979    0.331  134.927               4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Release to date and then extract year from it \n",
    "reg_df['release_date'] = pd.to_datetime(reg_df['release_date'])\n",
    "reg_df['release_date'] = reg_df['release_date'].dt.year\n",
    "reg_df.drop('release_date', axis=1, inplace=True) \n",
    "reg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 59770 to 93473\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        10000 non-null  int64  \n",
      " 1   duration_ms       10000 non-null  int64  \n",
      " 2   explicit          10000 non-null  int64  \n",
      " 3   danceability      10000 non-null  float64\n",
      " 4   energy            10000 non-null  float64\n",
      " 5   loudness          10000 non-null  float64\n",
      " 6   speechiness       10000 non-null  float64\n",
      " 7   acousticness      10000 non-null  float64\n",
      " 8   instrumentalness  10000 non-null  float64\n",
      " 9   liveness          10000 non-null  float64\n",
      " 10  valence           10000 non-null  float64\n",
      " 11  tempo             10000 non-null  float64\n",
      "dtypes: float64(9), int64(3)\n",
      "memory usage: 1015.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>34</td>\n",
       "      <td>198613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.746</td>\n",
       "      <td>-5.119</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.720</td>\n",
       "      <td>169.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>0</td>\n",
       "      <td>189013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-16.287</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.814</td>\n",
       "      <td>72.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>26</td>\n",
       "      <td>236160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-8.211</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.605</td>\n",
       "      <td>115.813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  loudness  \\\n",
       "59770           34       198613         0         0.695   0.746    -5.119   \n",
       "21362            0       189013         0         0.434   0.225   -16.287   \n",
       "127324          26       236160         0         0.697   0.695    -8.211   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "59770        0.3920        0.4040          0.000048    0.0979    0.720   \n",
       "21362        0.0418        0.9930          0.930000    0.2390    0.814   \n",
       "127324       0.0465        0.0325          0.008280    0.1140    0.605   \n",
       "\n",
       "          tempo  \n",
       "59770   169.813  \n",
       "21362    72.649  \n",
       "127324  115.813  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reg_df.drop(['name', 'artists','id','release_date', 'artists_id','genre','key','time_signature'], axis=1, inplace=True, errors='ignore') # Removing Categorical features with more then 10 unique values\n",
    "reg_df.info()\n",
    "reg_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable \n",
    "Xreg = reg_df.drop('popularity', axis=1) # features\n",
    "yreg = reg_df['popularity'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize the data as asked in question 9, although it creates a problem of data leakage as we are using the test data to fit the scaler\n",
    "scaler_reg = StandardScaler().fit(Xreg)\n",
    "Xreg_scaled = scaler_reg.transform(Xreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "Xreg_train_scaled, Xreg_test_scaled, yreg_train, yreg_test = train_test_split(Xreg, yreg, test_size=0.2, random_state=42)\n",
    "# end of Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lin_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to save and compare regression metrics \n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "def calculate_and_append_metrics(model_name, model, X_train, y_train, X_test, y_test, train_results_df, test_results_df):\n",
    "    # Calculate metrics for the training dataset\n",
    "    train_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_train, model.predict(X_train))],\n",
    "        'RMSE': [mean_squared_error(y_train, model.predict(X_train), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_train, model.predict(X_train))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_train, model.predict(X_train))]\n",
    "    })\n",
    "\n",
    "    # Calculate metrics for the test dataset\n",
    "    test_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_test, model.predict(X_test))],\n",
    "        'RMSE': [mean_squared_error(y_test, model.predict(X_test), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_test, model.predict(X_test))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_test, model.predict(X_test))]\n",
    "    })\n",
    "\n",
    "    # Concatenate metrics to the respective DataFrames\n",
    "    train_results_df = pd.concat([train_results_df, train_metrics], ignore_index=True)\n",
    "    test_results_df = pd.concat([test_results_df, test_metrics], ignore_index=True)\n",
    "\n",
    "    return train_results_df, test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>16.390692</td>\n",
       "      <td>13.333271</td>\n",
       "      <td>7.207390e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.214264  16.390692  13.333271  7.207390e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>16.912657</td>\n",
       "      <td>13.620896</td>\n",
       "      <td>7.177582e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.201381  16.912657  13.620896  7.177582e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "\n",
    "# Create empty DataFrames to store the results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame()\n",
    "\n",
    "# Calculate metrics for the Linear Regression model\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('Linear Regression', lin_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-263.523 total time=   0.0s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-276.441 total time=   0.0s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-266.625 total time=   0.0s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-289.154 total time=   0.0s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-252.761 total time=   0.0s\n",
      "[CV 1/5] END poly__degree=2;, score=-314267376111512230821888.000 total time=   0.0s\n",
      "[CV 2/5] END poly__degree=2;, score=-932116276046215774208.000 total time=   0.0s\n",
      "[CV 3/5] END poly__degree=2;, score=-1321455849821151833358336.000 total time=   0.0s\n",
      "[CV 4/5] END poly__degree=2;, score=-127048632761362356895744.000 total time=   0.0s\n",
      "[CV 5/5] END poly__degree=2;, score=-167432140955028553728.000 total time=   0.0s\n",
      "[CV 1/5] END poly__degree=3;, score=-3613012821950220115477845421432131996246178004992.000 total time=   0.8s\n",
      "[CV 2/5] END poly__degree=3;, score=-46395396560548952091066008963765598271741886464.000 total time=   1.1s\n",
      "[CV 3/5] END poly__degree=3;, score=-544089791702351629188382626675821419287348772864.000 total time=   0.7s\n",
      "[CV 4/5] END poly__degree=3;, score=-9887976517621602791903691658820514614416997613568.000 total time=   0.6s\n",
      "[CV 5/5] END poly__degree=3;, score=-11262167598767390535276871320228200569372017688576.000 total time=   0.5s\n",
      "[CV 1/5] END poly__degree=4;, score=-2926377514586926895731708897985883546449794946164158149567210412549586144909590528.000 total time=   6.4s\n",
      "[CV 2/5] END poly__degree=4;, score=-84664351580572550110688168966385778747338677323124824440905370656155535147008.000 total time=   5.6s\n",
      "[CV 3/5] END poly__degree=4;, score=-4564948410368998535381589925038859211054947437529516333017493709059331568173056.000 total time=   7.4s\n",
      "[CV 4/5] END poly__degree=4;, score=-704811001690054583292116282742712933263308204243072547866067208806797582270464.000 total time=   7.4s\n",
      "[CV 5/5] END poly__degree=4;, score=-5861538230265141307185526324925149772045679475767461440021477763456586171000291328.000 total time=   6.0s\n",
      "RidgeCV Results:\n",
      "Best Polynomial Degree: 1\n",
      "Best Alpha for RidgeCV: 1.0\n",
      "Best Negative MSE: 16.42257126799782\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ridge Regression \"\"\"\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "degrees = range(1, 5)\n",
    "\n",
    "# Create a RidgeCV model with cross-validation\n",
    "ridge_cv = RidgeCV([0.01, 0.1, 1, 10])\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('poly', poly),('ridge_cv', ridge_cv)])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "ridge_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error',verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "ridge_grid_search.fit(X, y)\n",
    "warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for RidgeCV\n",
    "best_degree = ridge_grid_search.best_params_['poly__degree']\n",
    "best_alpha = ridge_grid_search.best_estimator_.named_steps['ridge_cv'].alpha_\n",
    "\n",
    "# Print the results\n",
    "print(\"RidgeCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for RidgeCV:\", best_alpha)\n",
    "print(\"Best Negative MSE:\", (-ridge_grid_search.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-263.400 total time=   0.0s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-276.630 total time=   0.0s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-266.686 total time=   0.0s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-289.086 total time=   0.0s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-253.006 total time=   0.0s\n",
      "[CV 1/5] END .................poly__degree=2;, score=-241.196 total time=   0.7s\n",
      "[CV 2/5] END .................poly__degree=2;, score=-247.375 total time=   0.7s\n",
      "[CV 3/5] END .................poly__degree=2;, score=-251.092 total time=   0.6s\n",
      "[CV 4/5] END .................poly__degree=2;, score=-270.894 total time=   0.6s\n",
      "[CV 5/5] END .................poly__degree=2;, score=-236.734 total time=   0.6s\n",
      "/nLassoCV Results:\n",
      "Best Polynomial Degree: 2\n",
      "Best Polynomial Degree: 2\n",
      "Best Alpha for LassoCV: 0.01\n",
      "Best RMSE: 15.79424077243227\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lasso Regression\"\"\"\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "last_degree = 3\n",
    "degrees = range(1, last_degree)\n",
    "\n",
    "# Create a LassoCV model with cross-validation\n",
    "lasso_cv = LassoCV(alphas=[0.01,0.1, 1.0, 10.0]\n",
    "                #    max_iter=100000\n",
    "                   )\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('lasso_cv', lasso_cv)\n",
    "])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "lasso_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter out ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "lasso_grid_search.fit(X, y)\n",
    "\n",
    "# Optionally, you can reset the warning filters to their original state\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for LassoCV\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "best_alpha = lasso_grid_search.best_estimator_.named_steps['lasso_cv'].alpha_\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "\n",
    "# Print the results\n",
    "print(\"/nLassoCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for LassoCV:\", best_alpha)\n",
    "print(\"Best RMSE:\", (-lasso_grid_search.best_score_)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Words About Regularization\n",
    "\n",
    "The problem with a complex model of second order or higher is the risk of **Overfitting:**\n",
    "\n",
    "When a model fits the *noise* and random fluctuations in the training data rather than capturing the underlying patterns that are truly representative of the target population. \n",
    "\n",
    "A *solution* to the overfitting risk is **Regularization**: \n",
    "Adding a penalty term to the model's *loss function*, encouraging the model to have smaller parameter values or simpler parameter patterns, discourages overfitting.\n",
    "\n",
    "**Lasso (Least Absolute Shrinkage and Selection Operator):** adds a penalty term $||Î²||_1$ which is the sum of the absolute values of the coefficients.\n",
    "**Ridge** adds a penalty term $||Î²||_2^2$ which is the sum of the squared values of the coefficients.\n",
    "Lasso is better for Feature Selection and ridge is better for datasets with Multicollinearity, because Lasso tends to drive the coefficients of irrelevant features to exactly zero, effectively performing feature selection, while Ridge doesn't. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating polynomial regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>16.390692</td>\n",
       "      <td>13.333271</td>\n",
       "      <td>7.207390e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.214053</td>\n",
       "      <td>16.392894</td>\n",
       "      <td>13.336090</td>\n",
       "      <td>7.210138e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.281635</td>\n",
       "      <td>15.672253</td>\n",
       "      <td>12.666545</td>\n",
       "      <td>6.073200e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.214264  16.390692  13.333271  7.207390e+15\n",
       "1            RidgeCV  0.214053  16.392894  13.336090  7.210138e+15\n",
       "2            LassoCV  0.281635  15.672253  12.666545  6.073200e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>16.912657</td>\n",
       "      <td>13.620896</td>\n",
       "      <td>7.177582e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.201787</td>\n",
       "      <td>16.908353</td>\n",
       "      <td>13.622780</td>\n",
       "      <td>7.154488e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>16.187763</td>\n",
       "      <td>12.983852</td>\n",
       "      <td>6.464504e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.201381  16.912657  13.620896  7.177582e+15\n",
       "1            RidgeCV  0.201787  16.908353  13.622780  7.154488e+15\n",
       "2            LassoCV  0.268373  16.187763  12.983852  6.464504e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RidgeCV', ridge_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('LassoCV', lasso_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying RandomForrestRegressor and Xgbregressor\n",
    "We will use pre-tuned xgb and rf models and also hyperparameter tuned xgb and rf models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# run Xgboost regressor\n",
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-269.112 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-281.307 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-272.632 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-289.229 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-269.671 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-251.122 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-261.373 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-257.736 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-276.017 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-250.944 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-261.316 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-274.285 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-266.368 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-284.023 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-262.316 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-243.858 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-253.291 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-251.814 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-270.884 total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-243.247 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-256.852 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-269.257 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-263.985 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-280.602 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-257.104 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-240.198 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-248.785 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-251.592 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-268.963 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-239.202 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-232.920 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-241.301 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-245.862 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-265.714 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-230.380 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-232.820 total time=   0.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-240.191 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-246.350 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-264.698 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-229.757 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-235.127 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-237.379 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-244.617 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-263.736 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-229.769 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-238.513 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-238.293 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-246.420 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-267.220 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-230.870 total time=   0.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-236.925 total time=   0.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-238.056 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-249.645 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-263.266 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-230.653 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-243.854 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-240.607 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-252.658 total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-269.401 total time=   0.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-232.972 total time=   0.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-237.441 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-240.152 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-246.999 total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-266.286 total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-230.150 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-239.933 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-243.833 total time=   0.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-252.177 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-269.137 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-231.157 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-239.840 total time=   0.1s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-241.543 total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-254.128 total time=   0.1s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-270.783 total time=   0.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-233.588 total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-247.725 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-244.263 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-261.654 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-273.622 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-237.934 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-245.654 total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-249.860 total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-255.628 total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-278.772 total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-239.160 total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-259.514 total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-257.323 total time=   0.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-258.003 total time=   0.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-288.918 total time=   0.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-243.558 total time=   0.4s\n",
      "Best parameters for XGBoost:\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
      "Best RMSE for XGBoost: 15.560381196512669\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Tuning the XGBoost and Random Forest Regressors\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg_s = XGBRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_reg, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "xgb_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"Best parameters for XGBoost:\")\n",
    "print(xgb_grid_search.best_params_)\n",
    "print(\"Best RMSE for XGBoost:\", (-xgb_grid_search.best_score_) ** 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-257.184 total time=   1.6s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-267.335 total time=   1.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-266.972 total time=   1.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-282.835 total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-258.359 total time=   1.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-257.731 total time=   2.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-267.403 total time=   2.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-265.829 total time=   2.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-282.787 total time=   2.5s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-257.705 total time=   2.6s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-257.531 total time=   1.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-267.494 total time=   1.5s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-265.997 total time=   1.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-283.605 total time=   2.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-256.871 total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-257.578 total time=   2.5s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-267.026 total time=   2.3s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-266.388 total time=   2.5s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-282.924 total time=   2.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-258.479 total time=   2.6s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-257.363 total time=   1.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-266.699 total time=   1.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-266.706 total time=   1.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-282.990 total time=   1.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-258.066 total time=   1.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-257.098 total time=   2.5s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-267.542 total time=   3.8s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-266.190 total time=   2.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-282.935 total time=   2.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-258.274 total time=   2.9s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-249.198 total time=   1.5s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-258.390 total time=   2.1s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-258.174 total time=   1.9s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-278.159 total time=   1.9s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-249.052 total time=   1.7s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-248.520 total time=   3.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-258.541 total time=   4.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-258.231 total time=   4.1s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-277.626 total time=   5.2s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-249.001 total time=   3.5s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-248.977 total time=   1.8s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-258.442 total time=   2.0s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-258.555 total time=   1.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-278.329 total time=   1.7s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-249.387 total time=   1.5s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-248.893 total time=   3.1s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-259.006 total time=   3.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-258.479 total time=   5.1s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-278.467 total time=   4.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-248.646 total time=   3.5s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-248.715 total time=   1.9s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-258.444 total time=   1.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-258.348 total time=   1.6s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-278.773 total time=   1.9s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-249.154 total time=   1.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-248.905 total time=   3.6s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-259.219 total time=   3.5s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-257.910 total time=   3.5s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-278.005 total time=   3.4s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-248.403 total time=   4.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-243.522 total time=   2.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-251.803 total time=   2.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-254.116 total time=   2.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-273.587 total time=   2.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-242.705 total time=   2.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-242.902 total time=   4.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-251.713 total time=   4.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-253.624 total time=   4.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-273.815 total time=   4.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-243.241 total time=   4.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-242.991 total time=   2.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-252.118 total time=   2.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-253.789 total time=   1.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-272.633 total time=   1.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-242.396 total time=   1.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-243.401 total time=   3.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-252.141 total time=   3.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-253.722 total time=   3.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-273.799 total time=   4.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-242.689 total time=   3.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-243.666 total time=   1.7s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-252.673 total time=   1.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-253.483 total time=   2.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-273.202 total time=   2.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-243.553 total time=   2.2s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-243.440 total time=   4.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-252.220 total time=   4.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-253.732 total time=   4.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-273.213 total time=   3.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-242.886 total time=   3.8s\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "{'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best RMSE for Random Forest: 15.899228163310422\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest Regressor Hyperparameter Tuning\"\"\" \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [ 3,4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest regressor\n",
    "rf_reg_s = RandomForestRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_reg_s, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "rf_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "                   \n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"\\nBest parameters for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Best RMSE for Random Forest:\", (-rf_grid_search.best_score_) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating new regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>16.390692</td>\n",
       "      <td>13.333271</td>\n",
       "      <td>7.207390e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.214053</td>\n",
       "      <td>16.392894</td>\n",
       "      <td>13.336090</td>\n",
       "      <td>7.210138e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.281635</td>\n",
       "      <td>15.672253</td>\n",
       "      <td>12.666545</td>\n",
       "      <td>6.073200e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.899715</td>\n",
       "      <td>5.855660</td>\n",
       "      <td>4.616772</td>\n",
       "      <td>2.030969e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.817735</td>\n",
       "      <td>7.894246</td>\n",
       "      <td>5.984327</td>\n",
       "      <td>2.177899e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.302973</td>\n",
       "      <td>15.437744</td>\n",
       "      <td>12.434532</td>\n",
       "      <td>5.660471e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.419903</td>\n",
       "      <td>14.083454</td>\n",
       "      <td>11.266502</td>\n",
       "      <td>4.835413e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.214264  16.390692  13.333271  7.207390e+15\n",
       "1                      RidgeCV  0.214053  16.392894  13.336090  7.210138e+15\n",
       "2                      LassoCV  0.281635  15.672253  12.666545  6.073200e+15\n",
       "3        RandomForestRegressor  0.899715   5.855660   4.616772  2.030969e+15\n",
       "4                 XGBRegressor  0.817735   7.894246   5.984327  2.177899e+15\n",
       "5  RandomForestRegressor_tuned  0.302973  15.437744  12.434532  5.660471e+15\n",
       "6           XGBRegressor_tuned  0.419903  14.083454  11.266502  4.835413e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>16.912657</td>\n",
       "      <td>13.620896</td>\n",
       "      <td>7.177582e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.201787</td>\n",
       "      <td>16.908353</td>\n",
       "      <td>13.622780</td>\n",
       "      <td>7.154488e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>16.187763</td>\n",
       "      <td>12.983852</td>\n",
       "      <td>6.464504e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.307665</td>\n",
       "      <td>15.747080</td>\n",
       "      <td>12.367130</td>\n",
       "      <td>5.435473e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.245117</td>\n",
       "      <td>16.443025</td>\n",
       "      <td>12.831641</td>\n",
       "      <td>5.371123e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.269430</td>\n",
       "      <td>16.176066</td>\n",
       "      <td>12.916685</td>\n",
       "      <td>5.821930e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>15.829881</td>\n",
       "      <td>12.513830</td>\n",
       "      <td>5.475917e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.201381  16.912657  13.620896  7.177582e+15\n",
       "1                      RidgeCV  0.201787  16.908353  13.622780  7.154488e+15\n",
       "2                      LassoCV  0.268373  16.187763  12.983852  6.464504e+15\n",
       "3        RandomForestRegressor  0.307665  15.747080  12.367130  5.435473e+15\n",
       "4                 XGBRegressor  0.245117  16.443025  12.831641  5.371123e+15\n",
       "5  RandomForestRegressor_tuned  0.269430  16.176066  12.916685  5.821930e+15\n",
       "6           XGBRegressor_tuned  0.300365  15.829881  12.513830  5.475917e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics for the 4 latest models and append them to the results DataFrame \n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor', rf_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor', xgb_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor_tuned', rf_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor_tuned', xgb_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best model\n",
    "\n",
    "The best performing model is the XGBRegressor_tuned, with the lowest RMSE and MAE values on the test set, as well as the highest $R^2$ score.\n",
    "Except the non-tuned XGBRegressor, all of the models did not over-fit. Never the less, all of the models have low goodness of fit.\n",
    "\n",
    "* $R^2$ quantifies the proportion of the variance in the dependent variable that is explained by the independent variables in our model. In this case we witness poor fit. \n",
    "* Root Mean Square Error (RMSE) is a metric used to measure the average magnitude of the errors between predicted and actual values in a regression or forecasting problem, with lower values indicating better model accuracy. In our model we used RMSE as the main target function.\n",
    "* MAE provides a straightforward measure of how far, on average, the model's predictions are from the actual values. It helps assess the model's ability to make accurate predictions while considering both overestimations and underestimations equally. Our MAE values turned relatively low, indicating accurate models.\n",
    "* MAPE is a metric of the accuracy of predictions in relative terms. It tells us how much, on average, the predictions deviate from the actual values as a percentage of the actual values. All of our models reached small MAPE values, indicating relatively accurate predictions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
