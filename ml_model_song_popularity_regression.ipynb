{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Regression Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing general python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing libraries for data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importing libraries for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# importing libraries for model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "# importing libraries for model tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# importing tensorflow libraries for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset - Spotify Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "In this task, we will use a sample of 150K records, out of the [\"Spotify Dataset 1921-2020, 600k+ Tracks\"](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-19212020-600k-tracks?select=tracks.csv) which is available on kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns:\n",
    "\n",
    ">**Target Column** we will predict the following column:\n",
    "- `popularity` (Ranges from 0 to 100), float, representing the popularity of the song in the Spotify platform.\n",
    "\n",
    ">**Numerical Columns**:\n",
    "- `id` (Id of tracks generated by Spotify)\n",
    "- `acousticness` (Ranges from 0 to 1)\n",
    "- `danceability` (Ranges from 0 to 1)\n",
    "- `energy` (Ranges from 0 to 1)\n",
    "- `duration_ms` (Integer typically ranging from 200k to 300k)\n",
    "- `instrumentalness` (Ranges from 0 to 1)\n",
    "- `valence` (Ranges from 0 to 1)\n",
    "- `animality` (Ranges from 0 to 1)\n",
    "- `tempo` (Float typically ranging from 50 to 150)\n",
    "- `liveness` (Ranges from 0 to 1)\n",
    "- `loudness` (Float typically ranging from -60 to 0)\n",
    "- `speechiness` (Ranges from 0 to 1)\n",
    "- `release_year` a column which we are going to extract out of the `Release` column and predict based on song's features.\n",
    "\n",
    "\n",
    "> **Categorical Columns** (string types):\n",
    "- `explicit` (Whether the song is explicit (contains swearing or inappropriate language) or not)\n",
    "  \n",
    "> The following categorical columns will be removed to simplify the task (to many categories):\n",
    "- `artists` (List of artists mentioned)\n",
    "- `track_name` (Name of the song)\n",
    "- `genre` is the genre of the song. String type, Multiclass.<br>\n",
    "- `key` (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1, and so on…)\n",
    "- `time_signature` A notational convention to specify how many beats are in each bar (or measure). For example, rock music often has a time signature of 4/4, while classical music often has a time signature of 3/4 or 4/4.\n",
    "- `Release` the date which the song was released on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   id                150000 non-null  object \n",
      " 1   name              149984 non-null  object \n",
      " 2   popularity        150000 non-null  int64  \n",
      " 3   duration_ms       150000 non-null  int64  \n",
      " 4   explicit          150000 non-null  int64  \n",
      " 5   artists           150000 non-null  object \n",
      " 6   release_date      150000 non-null  object \n",
      " 7   danceability      150000 non-null  float64\n",
      " 8   energy            150000 non-null  float64\n",
      " 9   key               150000 non-null  int64  \n",
      " 10  loudness          150000 non-null  float64\n",
      " 11  speechiness       150000 non-null  float64\n",
      " 12  acousticness      150000 non-null  float64\n",
      " 13  instrumentalness  150000 non-null  float64\n",
      " 14  liveness          150000 non-null  float64\n",
      " 15  valence           150000 non-null  float64\n",
      " 16  tempo             150000 non-null  float64\n",
      " 17  time_signature    150000 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 20.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ot2x31QPJlJ4f6AM2yHlT</td>\n",
       "      <td>Amigo Mío (Homenaje a Juan Gabriel)</td>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>['Ana Gabriel']</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ooilm0qewfPaWkY93uEQ4</td>\n",
       "      <td>Ca C'est Gentil Ca C'est Pas Mal</td>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>['Pierrette Mad']</td>\n",
       "      <td>1925</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1FlNozP5jet4DrGU2Ava1l</td>\n",
       "      <td>เหมือนไม่เคย</td>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>['สุเทพ วงศ์กำแหง']</td>\n",
       "      <td>1992-04-01</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2KP3zqq9MQarh2WwsuonoM</td>\n",
       "      <td>Menino Bonito</td>\n",
       "      <td>50</td>\n",
       "      <td>166333</td>\n",
       "      <td>0</td>\n",
       "      <td>['Rita Lee']</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.775</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.253</td>\n",
       "      <td>178.251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4mKNBGNpDA7Ldu0fSyb7MX</td>\n",
       "      <td>Lekkerkry</td>\n",
       "      <td>31</td>\n",
       "      <td>191000</td>\n",
       "      <td>0</td>\n",
       "      <td>['ZAK VAN NIEKERK']</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.911</td>\n",
       "      <td>168.093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                 name  popularity  \\\n",
       "0  6ot2x31QPJlJ4f6AM2yHlT  Amigo Mío (Homenaje a Juan Gabriel)          25   \n",
       "1  5ooilm0qewfPaWkY93uEQ4     Ca C'est Gentil Ca C'est Pas Mal           0   \n",
       "2  1FlNozP5jet4DrGU2Ava1l                         เหมือนไม่เคย           8   \n",
       "3  2KP3zqq9MQarh2WwsuonoM                        Menino Bonito          50   \n",
       "4  4mKNBGNpDA7Ldu0fSyb7MX                            Lekkerkry          31   \n",
       "\n",
       "   duration_ms  explicit              artists release_date  danceability  \\\n",
       "0       219907         0      ['Ana Gabriel']         1991         0.673   \n",
       "1       181427         0    ['Pierrette Mad']         1925         0.520   \n",
       "2       181560         0  ['สุเทพ วงศ์กำแหง']   1992-04-01         0.654   \n",
       "3       166333         0         ['Rita Lee']   1974-01-01         0.247   \n",
       "4       191000         0  ['ZAK VAN NIEKERK']   2014-03-28         0.663   \n",
       "\n",
       "   energy  key  loudness  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.282    7   -14.247       0.0428         0.454          0.000000   \n",
       "1   0.359    0   -11.863       0.0817         0.988          0.000000   \n",
       "2   0.312    8   -17.238       0.0305         0.662          0.598000   \n",
       "3   0.426    0    -7.775       0.0316         0.725          0.000000   \n",
       "4   0.844    7    -4.548       0.0528         0.080          0.000005   \n",
       "\n",
       "   liveness  valence    tempo  time_signature  \n",
       "0     0.118    0.549  126.041               4  \n",
       "1     0.106    0.861   89.963               4  \n",
       "2     0.106    0.526   95.032               4  \n",
       "3     0.160    0.253  178.251               4  \n",
       "4     0.176    0.911  168.093               4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_url = 'https://raw.githubusercontent.com/FreeDataSets/DataPool/main/tracks_150000.csv' # this is the url for the dataset\n",
    "reg_df = pd.read_csv(reg_url)#.sample(100000,random_state=42) # In order to reduce the size of the dataset, we are taking a random sample of 5000 rows from the dataset\n",
    "\n",
    "# a preview of the dataframe\n",
    "reg_df.info() \n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ot2x31QPJlJ4f6AM2yHlT</td>\n",
       "      <td>Amigo Mío (Homenaje a Juan Gabriel)</td>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>['Ana Gabriel']</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ooilm0qewfPaWkY93uEQ4</td>\n",
       "      <td>Ca C'est Gentil Ca C'est Pas Mal</td>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>['Pierrette Mad']</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1FlNozP5jet4DrGU2Ava1l</td>\n",
       "      <td>เหมือนไม่เคย</td>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>['สุเทพ วงศ์กำแหง']</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2KP3zqq9MQarh2WwsuonoM</td>\n",
       "      <td>Menino Bonito</td>\n",
       "      <td>50</td>\n",
       "      <td>166333</td>\n",
       "      <td>0</td>\n",
       "      <td>['Rita Lee']</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.775</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.253</td>\n",
       "      <td>178.251</td>\n",
       "      <td>4</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4mKNBGNpDA7Ldu0fSyb7MX</td>\n",
       "      <td>Lekkerkry</td>\n",
       "      <td>31</td>\n",
       "      <td>191000</td>\n",
       "      <td>0</td>\n",
       "      <td>['ZAK VAN NIEKERK']</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.911</td>\n",
       "      <td>168.093</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                 name  popularity  \\\n",
       "0  6ot2x31QPJlJ4f6AM2yHlT  Amigo Mío (Homenaje a Juan Gabriel)          25   \n",
       "1  5ooilm0qewfPaWkY93uEQ4     Ca C'est Gentil Ca C'est Pas Mal           0   \n",
       "2  1FlNozP5jet4DrGU2Ava1l                         เหมือนไม่เคย           8   \n",
       "3  2KP3zqq9MQarh2WwsuonoM                        Menino Bonito          50   \n",
       "4  4mKNBGNpDA7Ldu0fSyb7MX                            Lekkerkry          31   \n",
       "\n",
       "   duration_ms  explicit              artists  danceability  energy  key  \\\n",
       "0       219907         0      ['Ana Gabriel']         0.673   0.282    7   \n",
       "1       181427         0    ['Pierrette Mad']         0.520   0.359    0   \n",
       "2       181560         0  ['สุเทพ วงศ์กำแหง']         0.654   0.312    8   \n",
       "3       166333         0         ['Rita Lee']         0.247   0.426    0   \n",
       "4       191000         0  ['ZAK VAN NIEKERK']         0.663   0.844    7   \n",
       "\n",
       "   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0   -14.247       0.0428         0.454          0.000000     0.118    0.549   \n",
       "1   -11.863       0.0817         0.988          0.000000     0.106    0.861   \n",
       "2   -17.238       0.0305         0.662          0.598000     0.106    0.526   \n",
       "3    -7.775       0.0316         0.725          0.000000     0.160    0.253   \n",
       "4    -4.548       0.0528         0.080          0.000005     0.176    0.911   \n",
       "\n",
       "     tempo  time_signature  release_year  release_month  \n",
       "0  126.041               4          1991              1  \n",
       "1   89.963               4          1925              1  \n",
       "2   95.032               4          1992              4  \n",
       "3  178.251               4          1974              1  \n",
       "4  168.093               4          2014              3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Release to date and then extract year from it \n",
    "reg_df['release_date'] = pd.to_datetime(reg_df['release_date'])\n",
    "reg_df['release_year'] = reg_df['release_date'].dt.year\n",
    "reg_df['release_month'] = reg_df['release_date'].dt.month\n",
    "reg_df.drop('release_date', axis=1, inplace=True) \n",
    "reg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   popularity        150000 non-null  int64  \n",
      " 1   duration_ms       150000 non-null  int64  \n",
      " 2   explicit          150000 non-null  int64  \n",
      " 3   danceability      150000 non-null  float64\n",
      " 4   energy            150000 non-null  float64\n",
      " 5   key               150000 non-null  int64  \n",
      " 6   loudness          150000 non-null  float64\n",
      " 7   speechiness       150000 non-null  float64\n",
      " 8   acousticness      150000 non-null  float64\n",
      " 9   instrumentalness  150000 non-null  float64\n",
      " 10  liveness          150000 non-null  float64\n",
      " 11  valence           150000 non-null  float64\n",
      " 12  tempo             150000 non-null  float64\n",
      " 13  time_signature    150000 non-null  int64  \n",
      " 14  release_year      150000 non-null  int64  \n",
      " 15  release_month     150000 non-null  int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 18.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>219907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.282</td>\n",
       "      <td>7</td>\n",
       "      <td>-14.247</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.549</td>\n",
       "      <td>126.041</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>181427</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.863</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.861</td>\n",
       "      <td>89.963</td>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>181560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.312</td>\n",
       "      <td>8</td>\n",
       "      <td>-17.238</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.526</td>\n",
       "      <td>95.032</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>166333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.775</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.253</td>\n",
       "      <td>178.251</td>\n",
       "      <td>4</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>191000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.844</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.548</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.911</td>\n",
       "      <td>168.093</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability  energy  key  loudness  \\\n",
       "0          25       219907         0         0.673   0.282    7   -14.247   \n",
       "1           0       181427         0         0.520   0.359    0   -11.863   \n",
       "2           8       181560         0         0.654   0.312    8   -17.238   \n",
       "3          50       166333         0         0.247   0.426    0    -7.775   \n",
       "4          31       191000         0         0.663   0.844    7    -4.548   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0428         0.454          0.000000     0.118    0.549  126.041   \n",
       "1       0.0817         0.988          0.000000     0.106    0.861   89.963   \n",
       "2       0.0305         0.662          0.598000     0.106    0.526   95.032   \n",
       "3       0.0316         0.725          0.000000     0.160    0.253  178.251   \n",
       "4       0.0528         0.080          0.000005     0.176    0.911  168.093   \n",
       "\n",
       "   time_signature  release_year  release_month  \n",
       "0               4          1991              1  \n",
       "1               4          1925              1  \n",
       "2               4          1992              4  \n",
       "3               4          1974              1  \n",
       "4               4          2014              3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.drop(['name', 'artists','id','release_date', 'artists_id','genre',], axis=1, inplace=True, errors='ignore') # Removing Categorical features with more then 10 unique values\n",
    "reg_df.info()\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target variable \n",
    "Xreg = reg_df.drop('popularity', axis=1) # features\n",
    "yreg = reg_df['popularity'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "Xreg_train, Xreg_test, yreg_train, yreg_test = train_test_split(Xreg, yreg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_reg = StandardScaler().fit(Xreg_train)\n",
    "Xreg_train_scaled = scaler_reg.transform(Xreg_train)\n",
    "Xreg_test_scaled = scaler_reg.transform(Xreg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression object\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lin_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to save and compare regression metrics \n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "def calculate_and_append_metrics(model_name, model, X_train, y_train, X_test, y_test, train_results_df, test_results_df):\n",
    "    # Calculate metrics for the training dataset\n",
    "    train_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_train, model.predict(X_train))],\n",
    "        'RMSE': [mean_squared_error(y_train, model.predict(X_train), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_train, model.predict(X_train))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_train, model.predict(X_train))]\n",
    "    })\n",
    "\n",
    "    # Calculate metrics for the test dataset\n",
    "    test_metrics = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'R2 Score': [r2_score(y_test, model.predict(X_test))],\n",
    "        'RMSE': [mean_squared_error(y_test, model.predict(X_test), squared=False)],\n",
    "        'MAE': [mean_absolute_error(y_test, model.predict(X_test))],\n",
    "        'MAPE': [mean_absolute_percentage_error(y_test, model.predict(X_test))]\n",
    "    })\n",
    "\n",
    "    # Concatenate metrics to the respective DataFrames\n",
    "    train_results_df = pd.concat([train_results_df, train_metrics], ignore_index=True)\n",
    "    test_results_df = pd.concat([test_results_df, test_metrics], ignore_index=True)\n",
    "\n",
    "    return train_results_df, test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>14.476721</td>\n",
       "      <td>11.146972</td>\n",
       "      <td>4.020286e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.379368  14.476721  11.146972  4.020286e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>14.69266</td>\n",
       "      <td>11.293555</td>\n",
       "      <td>4.288415e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score      RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.364608  14.69266  11.293555  4.288415e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "\n",
    "# Create empty DataFrames to store the results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame()\n",
    "\n",
    "# Calculate metrics for the Linear Regression model\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('Linear Regression', lin_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .................poly__degree=1;, score=-206.539 total time=   0.2s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-206.059 total time=   0.3s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-214.474 total time=   0.2s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-212.714 total time=   0.2s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-208.377 total time=   0.2s\n",
      "[CV 1/5] END .................poly__degree=2;, score=-193.044 total time=   4.1s\n",
      "[CV 2/5] END .................poly__degree=2;, score=-192.724 total time=   3.4s\n",
      "[CV 3/5] END .................poly__degree=2;, score=-201.650 total time=   3.5s\n",
      "[CV 4/5] END .................poly__degree=2;, score=-199.318 total time=   3.2s\n",
      "[CV 5/5] END .................poly__degree=2;, score=-194.684 total time=   3.4s\n",
      "RidgeCV Results:\n",
      "Best Polynomial Degree: 2\n",
      "Best Alpha for RidgeCV: 10.0\n",
      "Best Negative MSE: 14.010135583142546\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ridge Regression \"\"\"\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "degrees = range(1, 3)\n",
    "\n",
    "# Create a RidgeCV model with cross-validation\n",
    "ridge_cv = RidgeCV([0.01, 0.1, 1, 10])\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('poly', poly),('ridge_cv', ridge_cv)])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "ridge_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error',verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "ridge_grid_search.fit(X, y)\n",
    "warnings.filterwarnings(\"default\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for RidgeCV\n",
    "best_degree = ridge_grid_search.best_params_['poly__degree']\n",
    "best_alpha = ridge_grid_search.best_estimator_.named_steps['ridge_cv'].alpha_\n",
    "\n",
    "# Print the results\n",
    "print(\"RidgeCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for RidgeCV:\", best_alpha)\n",
    "print(\"Best Negative MSE:\", (-ridge_grid_search.best_score_)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END .................poly__degree=1;, score=-206.537 total time=   0.5s\n",
      "[CV 2/5] END .................poly__degree=1;, score=-206.062 total time=   0.4s\n",
      "[CV 3/5] END .................poly__degree=1;, score=-214.484 total time=   0.3s\n",
      "[CV 4/5] END .................poly__degree=1;, score=-212.711 total time=   0.3s\n",
      "[CV 5/5] END .................poly__degree=1;, score=-208.379 total time=   0.3s\n",
      "/nLassoCV Results:\n",
      "Best Polynomial Degree: 1\n",
      "Best Polynomial Degree: 1\n",
      "Best Alpha for LassoCV: 0.01\n",
      "Best RMSE: 14.478770678641188\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lasso Regression\"\"\"\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = Xreg_train_scaled\n",
    "y = yreg_train\n",
    "\n",
    "# Define the degrees to consider in the polynomial features\n",
    "last_degree = 2\n",
    "degrees = range(1, last_degree)\n",
    "\n",
    "# Create a LassoCV model with cross-validation\n",
    "lasso_cv = LassoCV(alphas=[0.01,0.1, 1.0, 10.0]\n",
    "                #    max_iter=100000\n",
    "                   )\n",
    "\n",
    "# Create a PolynomialFeatures transformer\n",
    "poly = PolynomialFeatures()\n",
    "\n",
    "# Perform a grid search over polynomial degrees\n",
    "param_grid = {'poly__degree': degrees}\n",
    "\n",
    "# Create a pipeline that combines PolynomialFeatures and LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('poly', poly),\n",
    "    ('lasso_cv', lasso_cv)\n",
    "])\n",
    "\n",
    "# Use GridSearchCV to find the best polynomial degree\n",
    "lasso_grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter out ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "lasso_grid_search.fit(X, y)\n",
    "\n",
    "# Optionally, you can reset the warning filters to their original state\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# Get the best polynomial degree and the best alpha for LassoCV\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "best_alpha = lasso_grid_search.best_estimator_.named_steps['lasso_cv'].alpha_\n",
    "best_degree = lasso_grid_search.best_params_['poly__degree']\n",
    "\n",
    "# Print the results\n",
    "print(\"/nLassoCV Results:\")\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Polynomial Degree:\", best_degree)\n",
    "print(\"Best Alpha for LassoCV:\", best_alpha)\n",
    "print(\"Best RMSE:\", (-lasso_grid_search.best_score_)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Words About Regularization\n",
    "\n",
    "The problem with a complex model of second order or higher is the risk of **Overfitting:**\n",
    "\n",
    "When a model fits the *noise* and random fluctuations in the training data rather than capturing the underlying patterns that are truly representative of the target population. \n",
    "\n",
    "A *solution* to the overfitting risk is **Regularization**: \n",
    "Adding a penalty term to the model's *loss function*, encouraging the model to have smaller parameter values or simpler parameter patterns, discourages overfitting.\n",
    "\n",
    "**Lasso (Least Absolute Shrinkage and Selection Operator):** adds a penalty term $||β||_1$ which is the sum of the absolute values of the coefficients.\n",
    "**Ridge** adds a penalty term $||β||_2^2$ which is the sum of the squared values of the coefficients.\n",
    "Lasso is better for Feature Selection and ridge is better for datasets with Multicollinearity, because Lasso tends to drive the coefficients of irrelevant features to exactly zero, effectively performing feature selection, while Ridge doesn't. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating polynomial regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>14.476721</td>\n",
       "      <td>11.146972</td>\n",
       "      <td>4.020286e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.420357</td>\n",
       "      <td>13.990506</td>\n",
       "      <td>10.809304</td>\n",
       "      <td>3.630854e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.379361</td>\n",
       "      <td>14.476797</td>\n",
       "      <td>11.146772</td>\n",
       "      <td>4.021165e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.379368  14.476721  11.146972  4.020286e+15\n",
       "1            RidgeCV  0.420357  13.990506  10.809304  3.630854e+15\n",
       "2            LassoCV  0.379361  14.476797  11.146772  4.021165e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>14.692660</td>\n",
       "      <td>11.293555</td>\n",
       "      <td>4.288415e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.408121</td>\n",
       "      <td>14.180653</td>\n",
       "      <td>10.941115</td>\n",
       "      <td>3.851846e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.364629</td>\n",
       "      <td>14.692417</td>\n",
       "      <td>11.293287</td>\n",
       "      <td>4.289202e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  R2 Score       RMSE        MAE          MAPE\n",
       "0  Linear Regression  0.364608  14.692660  11.293555  4.288415e+15\n",
       "1            RidgeCV  0.408121  14.180653  10.941115  3.851846e+15\n",
       "2            LassoCV  0.364629  14.692417  11.293287  4.289202e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model using the train and test set and different metrics\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RidgeCV', ridge_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('LassoCV', lasso_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying RandomForrestRegressor and Xgbregressor\n",
    "We will use pre-tuned xgb and rf models and also hyperparameter tuned xgb and rf models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# run Xgboost regressor\n",
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(Xreg_train_scaled, yreg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-218.508 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-219.373 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-225.924 total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-222.784 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-220.407 total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-195.326 total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-195.743 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-203.230 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-200.308 total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=-197.688 total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-212.936 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-213.843 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-220.421 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-217.578 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-215.203 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-190.823 total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-191.409 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-198.751 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-196.122 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=200;, score=-193.340 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-208.488 total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-209.492 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-216.076 total time=   1.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-213.254 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=-210.797 total time=   1.4s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-185.920 total time=   5.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-186.521 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-193.723 total time=   3.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-191.266 total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=-188.711 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-178.094 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-177.764 total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-186.768 total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-183.149 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=-180.538 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-173.949 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-174.284 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-183.036 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-179.465 total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=-176.528 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-172.599 total time=   1.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-173.480 total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-181.891 total time=   0.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-178.707 total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=-175.852 total time=   1.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-169.392 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-170.448 total time=   2.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-178.595 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-175.124 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=200;, score=-172.151 total time=   3.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-169.648 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-170.690 total time=   1.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-178.427 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-175.359 total time=   1.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=-171.922 total time=   3.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-167.355 total time=   5.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-167.924 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-175.569 total time=   1.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-172.753 total time=   2.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=-169.451 total time=   1.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-173.912 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-174.397 total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-182.731 total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-179.388 total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=100;, score=-176.431 total time=   0.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-170.701 total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-171.066 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-179.380 total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-175.724 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=3, n_estimators=200;, score=-173.393 total time=   0.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-170.015 total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-170.791 total time=   0.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-178.360 total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-175.824 total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=100;, score=-173.064 total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-167.963 total time=   1.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-168.622 total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-176.147 total time=   1.3s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-173.255 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=4, n_estimators=200;, score=-170.574 total time=   1.6s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-167.866 total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-168.163 total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-176.762 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-173.194 total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=-170.144 total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-166.958 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-167.814 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-175.921 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-172.487 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=200;, score=-169.375 total time=   1.6s\n",
      "Best parameters for XGBoost:\n",
      "{'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best RMSE for XGBoost: 13.057978734821887\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyperparameter Tuning the XGBoost and Random Forest Regressors\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg_s = XGBRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_reg, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "xgb_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"Best parameters for XGBoost:\")\n",
    "print(xgb_grid_search.best_params_)\n",
    "print(\"Best RMSE for XGBoost:\", (-xgb_grid_search.best_score_) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-205.082 total time=  27.5s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-203.947 total time=  28.9s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-212.118 total time=  22.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-209.800 total time=  25.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=100;, score=-206.726 total time=  23.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-205.211 total time=  46.9s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-203.881 total time=  56.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-212.173 total time=  45.9s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-209.787 total time=  54.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=200;, score=-206.824 total time=  46.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-205.055 total time=  25.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-203.876 total time=  25.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-212.060 total time=  23.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-209.790 total time=  21.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=100;, score=-206.790 total time=  32.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-205.141 total time=  41.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-203.937 total time=  35.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-212.229 total time=  35.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-209.785 total time=  34.8s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=5, n_estimators=200;, score=-206.778 total time=  36.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-204.974 total time=  17.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-203.935 total time=  17.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-212.220 total time=  17.8s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-209.599 total time=  17.5s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=100;, score=-206.828 total time=  20.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-205.106 total time= 1.2min\n",
      "[CV 2/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-203.936 total time=  50.8s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-212.196 total time=  52.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-209.755 total time=  46.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=10, n_estimators=200;, score=-206.718 total time= 1.0min\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-196.345 total time=  31.4s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-195.181 total time=  44.9s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-203.832 total time=  25.4s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-201.718 total time=  40.3s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=100;, score=-198.467 total time=  39.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-196.430 total time= 1.2min\n",
      "[CV 2/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-195.082 total time=  52.6s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-203.951 total time= 1.0min\n",
      "[CV 4/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-201.652 total time= 1.0min\n",
      "[CV 5/5] END max_depth=4, min_samples_split=2, n_estimators=200;, score=-198.437 total time=  54.1s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-196.573 total time=  31.5s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-195.117 total time=  31.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-203.857 total time=  27.8s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-201.671 total time=  27.7s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=100;, score=-198.512 total time=  29.2s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-196.412 total time= 1.1min\n",
      "[CV 2/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-195.125 total time=  56.4s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-203.906 total time=  52.0s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-201.693 total time= 1.1min\n",
      "[CV 5/5] END max_depth=4, min_samples_split=5, n_estimators=200;, score=-198.423 total time=  58.6s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-196.408 total time=  25.8s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-195.144 total time=  28.1s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-203.929 total time=  28.2s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-201.559 total time=  29.0s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=100;, score=-198.512 total time=  27.4s\n",
      "[CV 1/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-196.313 total time=  49.9s\n",
      "[CV 2/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-195.155 total time=  53.2s\n",
      "[CV 3/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-203.814 total time=  52.7s\n",
      "[CV 4/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-201.742 total time=  49.5s\n",
      "[CV 5/5] END max_depth=4, min_samples_split=10, n_estimators=200;, score=-198.453 total time=  53.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-190.815 total time=  32.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-189.226 total time=  31.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-198.765 total time=  31.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-196.343 total time=  33.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=-192.603 total time=  32.8s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-190.682 total time= 1.0min\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-189.337 total time= 1.1min\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-198.695 total time= 1.1min\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-196.322 total time=  56.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=-192.564 total time= 1.1min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-190.819 total time=  32.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-189.278 total time=  31.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-198.630 total time=  44.4s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-196.292 total time=  38.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=-192.589 total time=  41.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-190.922 total time= 1.1min\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-189.212 total time= 1.2min\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-198.708 total time= 1.2min\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-196.283 total time= 1.1min\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=-192.506 total time= 1.1min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-190.863 total time=  39.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-189.313 total time=  35.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-198.718 total time=  28.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-196.224 total time=  27.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=-192.781 total time=  27.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-190.849 total time=  56.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-189.316 total time= 1.1min\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-198.701 total time= 1.2min\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-196.328 total time= 1.2min\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=-192.684 total time= 1.0min\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best RMSE for Random Forest: 13.911138403975112\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest Regressor Hyperparameter Tuning\"\"\" \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [ 3,4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest regressor\n",
    "rf_reg_s = RandomForestRegressor()\n",
    "\n",
    "# Create a GridSearchCV instance for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_reg_s, param_grid=rf_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "rf_grid_search.fit(Xreg_train_scaled, yreg_train)\n",
    "                   \n",
    "\n",
    "# Print the best parameters and the corresponding RMSE\n",
    "print(\"\\nBest parameters for Random Forest:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Best RMSE for Random Forest:\", (-rf_grid_search.best_score_) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating new regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>14.476721</td>\n",
       "      <td>11.146972</td>\n",
       "      <td>4.020286e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.420357</td>\n",
       "      <td>13.990506</td>\n",
       "      <td>10.809304</td>\n",
       "      <td>3.630854e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.379361</td>\n",
       "      <td>14.476797</td>\n",
       "      <td>11.146772</td>\n",
       "      <td>4.021165e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.929776</td>\n",
       "      <td>4.869643</td>\n",
       "      <td>3.629849</td>\n",
       "      <td>8.400674e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.582000</td>\n",
       "      <td>11.880669</td>\n",
       "      <td>8.986569</td>\n",
       "      <td>1.976237e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.428732</td>\n",
       "      <td>13.889061</td>\n",
       "      <td>10.503918</td>\n",
       "      <td>2.890572e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.558086</td>\n",
       "      <td>12.215797</td>\n",
       "      <td>9.252229</td>\n",
       "      <td>2.099336e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.379368  14.476721  11.146972  4.020286e+15\n",
       "1                      RidgeCV  0.420357  13.990506  10.809304  3.630854e+15\n",
       "2                      LassoCV  0.379361  14.476797  11.146772  4.021165e+15\n",
       "3        RandomForestRegressor  0.929776   4.869643   3.629849  8.400674e+14\n",
       "4                 XGBRegressor  0.582000  11.880669   8.986569  1.976237e+15\n",
       "5  RandomForestRegressor_tuned  0.428732  13.889061  10.503918  2.890572e+15\n",
       "6           XGBRegressor_tuned  0.558086  12.215797   9.252229  2.099336e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------- \n",
      "\n",
      "Test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.364608</td>\n",
       "      <td>14.692660</td>\n",
       "      <td>11.293555</td>\n",
       "      <td>4.288415e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.408121</td>\n",
       "      <td>14.180653</td>\n",
       "      <td>10.941115</td>\n",
       "      <td>3.851846e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>0.364629</td>\n",
       "      <td>14.692417</td>\n",
       "      <td>11.293287</td>\n",
       "      <td>4.289202e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.501104</td>\n",
       "      <td>13.019212</td>\n",
       "      <td>9.800499</td>\n",
       "      <td>2.439984e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.487759</td>\n",
       "      <td>13.192184</td>\n",
       "      <td>9.928907</td>\n",
       "      <td>2.537362e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor_tuned</td>\n",
       "      <td>0.419436</td>\n",
       "      <td>14.044447</td>\n",
       "      <td>10.610486</td>\n",
       "      <td>3.087203e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor_tuned</td>\n",
       "      <td>0.495152</td>\n",
       "      <td>13.096637</td>\n",
       "      <td>9.885771</td>\n",
       "      <td>2.508373e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R2 Score       RMSE        MAE          MAPE\n",
       "0            Linear Regression  0.364608  14.692660  11.293555  4.288415e+15\n",
       "1                      RidgeCV  0.408121  14.180653  10.941115  3.851846e+15\n",
       "2                      LassoCV  0.364629  14.692417  11.293287  4.289202e+15\n",
       "3        RandomForestRegressor  0.501104  13.019212   9.800499  2.439984e+15\n",
       "4                 XGBRegressor  0.487759  13.192184   9.928907  2.537362e+15\n",
       "5  RandomForestRegressor_tuned  0.419436  14.044447  10.610486  3.087203e+15\n",
       "6           XGBRegressor_tuned  0.495152  13.096637   9.885771  2.508373e+15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics for the 4 latest models and append them to the results DataFrame \n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor', rf_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor', xgb_reg, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('RandomForestRegressor_tuned', rf_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "train_results_df, test_results_df = calculate_and_append_metrics('XGBRegressor_tuned', xgb_grid_search.best_estimator_, Xreg_train_scaled, yreg_train, Xreg_test_scaled, yreg_test, train_results_df, test_results_df)\n",
    "\n",
    "# display the results\n",
    "print(\"Train:\")\n",
    "display(train_results_df)\n",
    "print(\"-\"*70,\"\\n\")\n",
    "print(\"Test:\")\n",
    "display(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best model\n",
    "\n",
    "The best performing model is the RandomForestRegressor, with the lowest RMSE and MAE values on the test set, as well as the highest $R^2$ score.\n",
    "\n",
    "* $R^2$ quantifies the proportion of the variance in the dependent variable that is explained by the independent variables in our model. In this case we witness poor fit. \n",
    "* Root Mean Square Error (RMSE) is a metric used to measure the average magnitude of the errors between predicted and actual values in a regression or forecasting problem, with lower values indicating better model accuracy. In our model we used RMSE as the main target function.\n",
    "* MAE provides a straightforward measure of how far, on average, the model's predictions are from the actual values. It helps assess the model's ability to make accurate predictions while considering both overestimations and underestimations equally. Our MAE values turned relatively low, indicating accurate models.\n",
    "* MAPE is a metric of the accuracy of predictions in relative terms. It tells us how much, on average, the predictions deviate from the actual values as a percentage of the actual values. All of our models reached small MAPE values, indicating relatively accurate predictions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
